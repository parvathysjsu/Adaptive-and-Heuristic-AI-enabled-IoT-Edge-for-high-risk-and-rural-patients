{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# importing train_test_split model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "all_data = pd.read_csv('./all_data1all3.csv')\n",
    "#print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_data_x = []\n",
    "_all_data_y = []    \n",
    "count = all_data.shape[0] \n",
    "count1 = all_data.shape[1]\n",
    "\n",
    "for i in range(0,count):\n",
    "    _all_data_x.append(all_data.iloc[i, 0:58])\n",
    "    _all_data_y.append(all_data.iloc[i, 58:59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(_all_data_x, _all_data_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "feature_number = len(X_train[0])\n",
    "print(feature_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2559, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2559, 58)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f21398acf1cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "#y_train = np.reshape(y_train.values, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = keras.Sequential()\n",
    "regressor.add(layers.InputLayer(input_shape=(feature_number,)))\n",
    "regressor.add(layers.Dense(units=64,activation = 'relu'))\n",
    "regressor.add(layers.Dense(units=1,activation='linear'))\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1054.1724\n",
      "Epoch 2/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 11.7024\n",
      "Epoch 3/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.7309\n",
      "Epoch 4/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 2.4129\n",
      "Epoch 5/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.3685\n",
      "Epoch 6/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.9343\n",
      "Epoch 7/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7279\n",
      "Epoch 8/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5765\n",
      "Epoch 9/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5261\n",
      "Epoch 10/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4549\n",
      "Epoch 11/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4147\n",
      "Epoch 12/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3514\n",
      "Epoch 13/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3146\n",
      "Epoch 14/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2919\n",
      "Epoch 15/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2830\n",
      "Epoch 16/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3076\n",
      "Epoch 17/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2301\n",
      "Epoch 18/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2062\n",
      "Epoch 19/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2097A: 0s - loss: 0.20\n",
      "Epoch 20/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2230\n",
      "Epoch 21/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1916\n",
      "Epoch 22/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1705\n",
      "Epoch 23/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2008\n",
      "Epoch 24/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2309\n",
      "Epoch 25/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2540\n",
      "Epoch 26/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3649\n",
      "Epoch 27/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2139\n",
      "Epoch 28/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.1052\n",
      "Epoch 29/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.0717\n",
      "Epoch 30/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 1.2617\n",
      "Epoch 31/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6650\n",
      "Epoch 32/400\n",
      "80/80 [==============================] - 0s 960us/step - loss: 0.3468\n",
      "Epoch 33/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.2840\n",
      "Epoch 34/400\n",
      "80/80 [==============================] - 0s 997us/step - loss: 0.2374\n",
      "Epoch 35/400\n",
      "80/80 [==============================] - 0s 950us/step - loss: 0.2090\n",
      "Epoch 36/400\n",
      "80/80 [==============================] - 0s 976us/step - loss: 0.2064\n",
      "Epoch 37/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2341\n",
      "Epoch 38/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2472\n",
      "Epoch 39/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1824\n",
      "Epoch 40/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1524\n",
      "Epoch 41/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1242\n",
      "Epoch 42/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.1032\n",
      "Epoch 43/400\n",
      "80/80 [==============================] - 0s 960us/step - loss: 0.0939\n",
      "Epoch 44/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.0816\n",
      "Epoch 45/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 46/400\n",
      "80/80 [==============================] - 0s 997us/step - loss: 0.0930\n",
      "Epoch 47/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0930\n",
      "Epoch 48/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0799\n",
      "Epoch 49/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0890\n",
      "Epoch 50/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0822\n",
      "Epoch 51/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.1113\n",
      "Epoch 52/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.2948\n",
      "Epoch 53/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.4418\n",
      "Epoch 54/400\n",
      "80/80 [==============================] - 0s 952us/step - loss: 1.6817\n",
      "Epoch 55/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 1.2578\n",
      "Epoch 56/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.9391\n",
      "Epoch 57/400\n",
      "80/80 [==============================] - 0s 898us/step - loss: 0.6336\n",
      "Epoch 58/400\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.3494\n",
      "Epoch 59/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2769\n",
      "Epoch 60/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1931\n",
      "Epoch 61/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2329\n",
      "Epoch 62/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.1079\n",
      "Epoch 63/400\n",
      "80/80 [==============================] - 0s 957us/step - loss: 0.0874\n",
      "Epoch 64/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.1332\n",
      "Epoch 65/400\n",
      "80/80 [==============================] - 0s 940us/step - loss: 0.0691\n",
      "Epoch 66/400\n",
      "80/80 [==============================] - 0s 922us/step - loss: 0.0602\n",
      "Epoch 67/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.0700\n",
      "Epoch 68/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.0788\n",
      "Epoch 69/400\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.1097\n",
      "Epoch 70/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.0977\n",
      "Epoch 71/400\n",
      "80/80 [==============================] - 0s 898us/step - loss: 0.2142\n",
      "Epoch 72/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.1147\n",
      "Epoch 73/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.3721\n",
      "Epoch 74/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.5031\n",
      "Epoch 75/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.3629\n",
      "Epoch 76/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.7047\n",
      "Epoch 77/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9065\n",
      "Epoch 78/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.7144\n",
      "Epoch 79/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4247\n",
      "Epoch 80/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2884\n",
      "Epoch 81/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1886\n",
      "Epoch 82/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1023\n",
      "Epoch 83/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1473\n",
      "Epoch 84/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0704\n",
      "Epoch 85/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1317\n",
      "Epoch 86/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1448\n",
      "Epoch 87/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1482\n",
      "Epoch 88/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1099\n",
      "Epoch 89/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1650\n",
      "Epoch 90/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1342\n",
      "Epoch 91/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1846\n",
      "Epoch 92/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1420\n",
      "Epoch 93/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2587\n",
      "Epoch 94/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5455\n",
      "Epoch 95/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5395\n",
      "Epoch 96/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0114\n",
      "Epoch 97/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9438\n",
      "Epoch 98/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9644\n",
      "Epoch 99/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0158\n",
      "Epoch 100/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2858\n",
      "Epoch 101/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1882\n",
      "Epoch 102/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0768\n",
      "Epoch 103/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1498\n",
      "Epoch 104/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0876\n",
      "Epoch 105/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.0734\n",
      "Epoch 106/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0688\n",
      "Epoch 107/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1095\n",
      "Epoch 108/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1231\n",
      "Epoch 109/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0990\n",
      "Epoch 110/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1416\n",
      "Epoch 111/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1365\n",
      "Epoch 112/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2101\n",
      "Epoch 113/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2564\n",
      "Epoch 114/400\n",
      "80/80 [==============================] - 0s 960us/step - loss: 0.3367\n",
      "Epoch 115/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0764\n",
      "Epoch 116/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3441\n",
      "Epoch 117/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1329\n",
      "Epoch 118/400\n",
      "80/80 [==============================] - 0s 949us/step - loss: 0.1659\n",
      "Epoch 119/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5668\n",
      "Epoch 120/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7026\n",
      "Epoch 121/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4782\n",
      "Epoch 122/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6765\n",
      "Epoch 123/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3257\n",
      "Epoch 124/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4768\n",
      "Epoch 125/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4221\n",
      "Epoch 126/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3642\n",
      "Epoch 127/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4111\n",
      "Epoch 128/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2668\n",
      "Epoch 129/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.0993\n",
      "Epoch 130/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0870\n",
      "Epoch 131/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0635\n",
      "Epoch 132/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0576\n",
      "Epoch 133/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1079\n",
      "Epoch 134/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0939\n",
      "Epoch 135/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.2582\n",
      "Epoch 136/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7242\n",
      "Epoch 137/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2125\n",
      "Epoch 138/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3051\n",
      "Epoch 139/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1320\n",
      "Epoch 140/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1409\n",
      "Epoch 141/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1466\n",
      "Epoch 142/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1131\n",
      "Epoch 143/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2108\n",
      "Epoch 144/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4787\n",
      "Epoch 145/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5539\n",
      "Epoch 146/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4209\n",
      "Epoch 147/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0895\n",
      "Epoch 148/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0444\n",
      "Epoch 149/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0536\n",
      "Epoch 150/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0628\n",
      "Epoch 151/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1039\n",
      "Epoch 152/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1069\n",
      "Epoch 153/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.0837\n",
      "Epoch 154/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2696\n",
      "Epoch 155/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4416\n",
      "Epoch 156/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9650\n",
      "Epoch 157/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4538\n",
      "Epoch 158/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4606\n",
      "Epoch 159/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4895\n",
      "Epoch 160/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2845\n",
      "Epoch 161/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1298\n",
      "Epoch 162/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1353\n",
      "Epoch 163/400\n",
      "80/80 [==============================] - 0s 997us/step - loss: 0.0620\n",
      "Epoch 164/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 165/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0725\n",
      "Epoch 166/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1793\n",
      "Epoch 167/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1014\n",
      "Epoch 168/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0574\n",
      "Epoch 169/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1027\n",
      "Epoch 170/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0949\n",
      "Epoch 171/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1734\n",
      "Epoch 172/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0761\n",
      "Epoch 173/400\n",
      "80/80 [==============================] - 0s 985us/step - loss: 0.1966\n",
      "Epoch 174/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2273\n",
      "Epoch 175/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1795\n",
      "Epoch 176/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5001\n",
      "Epoch 177/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3274\n",
      "Epoch 178/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2457\n",
      "Epoch 179/400\n",
      "80/80 [==============================] - 0s 997us/step - loss: 0.2797\n",
      "Epoch 180/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2626\n",
      "Epoch 181/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1976\n",
      "Epoch 182/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2858\n",
      "Epoch 183/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1023\n",
      "Epoch 184/400\n",
      "80/80 [==============================] - 0s 985us/step - loss: 0.1720\n",
      "Epoch 185/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1319\n",
      "Epoch 186/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1499\n",
      "Epoch 187/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2307\n",
      "Epoch 188/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.1852\n",
      "Epoch 189/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1369\n",
      "Epoch 190/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0815\n",
      "Epoch 191/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1409\n",
      "Epoch 192/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1244\n",
      "Epoch 193/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3033\n",
      "Epoch 194/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2606\n",
      "Epoch 195/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.4218\n",
      "Epoch 196/400\n",
      "80/80 [==============================] - 0s 893us/step - loss: 0.3978\n",
      "Epoch 197/400\n",
      "80/80 [==============================] - 0s 901us/step - loss: 0.1811\n",
      "Epoch 198/400\n",
      "80/80 [==============================] - 0s 947us/step - loss: 0.3668\n",
      "Epoch 199/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2672\n",
      "Epoch 200/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3256\n",
      "Epoch 201/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.3421\n",
      "Epoch 202/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.1587\n",
      "Epoch 203/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1090\n",
      "Epoch 204/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0799\n",
      "Epoch 205/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1326\n",
      "Epoch 206/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0506\n",
      "Epoch 207/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1319\n",
      "Epoch 208/400\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0956\n",
      "Epoch 209/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0460\n",
      "Epoch 210/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0928\n",
      "Epoch 211/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 212/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0430\n",
      "Epoch 213/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2878\n",
      "Epoch 214/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0852\n",
      "Epoch 215/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.0515\n",
      "Epoch 216/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2317\n",
      "Epoch 217/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0660\n",
      "Epoch 218/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0836\n",
      "Epoch 219/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0817\n",
      "Epoch 220/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0984\n",
      "Epoch 221/400\n",
      "80/80 [==============================] - 0s 885us/step - loss: 0.0603\n",
      "Epoch 222/400\n",
      "80/80 [==============================] - 0s 900us/step - loss: 0.1452\n",
      "Epoch 223/400\n",
      "80/80 [==============================] - 0s 960us/step - loss: 0.2192\n",
      "Epoch 224/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2553\n",
      "Epoch 225/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2696\n",
      "Epoch 226/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1976\n",
      "Epoch 227/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3726\n",
      "Epoch 228/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5227\n",
      "Epoch 229/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4393\n",
      "Epoch 230/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4369\n",
      "Epoch 231/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1207\n",
      "Epoch 232/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0481\n",
      "Epoch 233/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0895\n",
      "Epoch 234/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1165\n",
      "Epoch 235/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2613\n",
      "Epoch 236/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.5210\n",
      "Epoch 237/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0405\n",
      "Epoch 238/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0384A: 0s - loss: 0.038\n",
      "Epoch 239/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1038\n",
      "Epoch 240/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 241/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0260\n",
      "Epoch 242/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0325\n",
      "Epoch 243/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0584\n",
      "Epoch 244/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0778\n",
      "Epoch 245/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1666\n",
      "Epoch 246/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.2061\n",
      "Epoch 247/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.2723\n",
      "Epoch 248/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1029\n",
      "Epoch 249/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2780\n",
      "Epoch 250/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2517\n",
      "Epoch 251/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3788\n",
      "Epoch 252/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2128\n",
      "Epoch 253/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1452\n",
      "Epoch 254/400\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.1652\n",
      "Epoch 255/400\n",
      "80/80 [==============================] - 0s 898us/step - loss: 0.1412\n",
      "Epoch 256/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.1503\n",
      "Epoch 257/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2052\n",
      "Epoch 258/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1402\n",
      "Epoch 259/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1873\n",
      "Epoch 260/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1599\n",
      "Epoch 261/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2821\n",
      "Epoch 262/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3298\n",
      "Epoch 263/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1585\n",
      "Epoch 264/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2006\n",
      "Epoch 265/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1327\n",
      "Epoch 266/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0874\n",
      "Epoch 267/400\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.0493\n",
      "Epoch 268/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1251\n",
      "Epoch 269/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1287\n",
      "Epoch 270/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1599\n",
      "Epoch 271/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0721\n",
      "Epoch 272/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0784\n",
      "Epoch 273/400\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.1009\n",
      "Epoch 274/400\n",
      "80/80 [==============================] - 0s 923us/step - loss: 0.0707\n",
      "Epoch 275/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0754\n",
      "Epoch 276/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0555\n",
      "Epoch 277/400\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.1822\n",
      "Epoch 278/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2382\n",
      "Epoch 279/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1997\n",
      "Epoch 280/400\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.2228\n",
      "Epoch 281/400\n",
      "80/80 [==============================] - 0s 962us/step - loss: 0.3371\n",
      "Epoch 282/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2514\n",
      "Epoch 283/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2260\n",
      "Epoch 284/400\n",
      "80/80 [==============================] - 0s 898us/step - loss: 0.1799\n",
      "Epoch 285/400\n",
      "80/80 [==============================] - 0s 885us/step - loss: 0.2091\n",
      "Epoch 286/400\n",
      "80/80 [==============================] - 0s 898us/step - loss: 0.1485\n",
      "Epoch 287/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2637\n",
      "Epoch 288/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1144\n",
      "Epoch 289/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0380\n",
      "Epoch 290/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.5801\n",
      "Epoch 291/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1205\n",
      "Epoch 292/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 293/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0347\n",
      "Epoch 294/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0274\n",
      "Epoch 295/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 296/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0270\n",
      "Epoch 297/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0391\n",
      "Epoch 298/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1129\n",
      "Epoch 299/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4352\n",
      "Epoch 300/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4897\n",
      "Epoch 301/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4101\n",
      "Epoch 302/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2886\n",
      "Epoch 303/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2087\n",
      "Epoch 304/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2289\n",
      "Epoch 305/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1072\n",
      "Epoch 306/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2529\n",
      "Epoch 307/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2327\n",
      "Epoch 308/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6045\n",
      "Epoch 309/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2693\n",
      "Epoch 310/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1381\n",
      "Epoch 311/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0487\n",
      "Epoch 312/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0363\n",
      "Epoch 313/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0487\n",
      "Epoch 314/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0614\n",
      "Epoch 315/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0317\n",
      "Epoch 316/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0720\n",
      "Epoch 317/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 318/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0902\n",
      "Epoch 319/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2263\n",
      "Epoch 320/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1732\n",
      "Epoch 321/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1906\n",
      "Epoch 322/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1283\n",
      "Epoch 323/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1727\n",
      "Epoch 324/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4641\n",
      "Epoch 325/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2220\n",
      "Epoch 326/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1476\n",
      "Epoch 327/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 328/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0878\n",
      "Epoch 329/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0518\n",
      "Epoch 330/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0539\n",
      "Epoch 331/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0521\n",
      "Epoch 332/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1261\n",
      "Epoch 333/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0805\n",
      "Epoch 334/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0937\n",
      "Epoch 335/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0688\n",
      "Epoch 336/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0830\n",
      "Epoch 337/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0848\n",
      "Epoch 338/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2249\n",
      "Epoch 339/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1812\n",
      "Epoch 340/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3228\n",
      "Epoch 341/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2586\n",
      "Epoch 342/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5884\n",
      "Epoch 343/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1986\n",
      "Epoch 344/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2180\n",
      "Epoch 345/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1127\n",
      "Epoch 346/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0994\n",
      "Epoch 347/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0908\n",
      "Epoch 348/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0406\n",
      "Epoch 349/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0694\n",
      "Epoch 350/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0389\n",
      "Epoch 351/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0429\n",
      "Epoch 352/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1001\n",
      "Epoch 353/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0526\n",
      "Epoch 354/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2510\n",
      "Epoch 355/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0933\n",
      "Epoch 356/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1308\n",
      "Epoch 357/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3939\n",
      "Epoch 358/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2329\n",
      "Epoch 359/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3214\n",
      "Epoch 360/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1483\n",
      "Epoch 361/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1980\n",
      "Epoch 362/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1670\n",
      "Epoch 363/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1068\n",
      "Epoch 364/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0772\n",
      "Epoch 365/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0587\n",
      "Epoch 366/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1361\n",
      "Epoch 367/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1354\n",
      "Epoch 368/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0427\n",
      "Epoch 369/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0639\n",
      "Epoch 370/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "Epoch 371/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1760\n",
      "Epoch 372/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0849\n",
      "Epoch 373/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0706\n",
      "Epoch 374/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379\n",
      "Epoch 375/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0520\n",
      "Epoch 376/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1078\n",
      "Epoch 377/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0390\n",
      "Epoch 378/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 379/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3210\n",
      "Epoch 380/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2295\n",
      "Epoch 381/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1492\n",
      "Epoch 382/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1151\n",
      "Epoch 383/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0378\n",
      "Epoch 384/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0514\n",
      "Epoch 385/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0699\n",
      "Epoch 386/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5316\n",
      "Epoch 387/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6933\n",
      "Epoch 388/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2092\n",
      "Epoch 389/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1579\n",
      "Epoch 390/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0776\n",
      "Epoch 391/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0510\n",
      "Epoch 392/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0415\n",
      "Epoch 393/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 394/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0306\n",
      "Epoch 395/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "Epoch 396/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 397/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.0326\n",
      "Epoch 398/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1693\n",
      "Epoch 400/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0660\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results=regressor.fit(X_train,y_train,epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "y_pred= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred > 1.5, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165,   2],\n",
       "       [  3, 470]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\parva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\parva\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\parva\\AppData\\Local\\Temp\\tmpx5zjuaml\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16496"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(regressor)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "open('ml_fall_model.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the TensorFlow Lite model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array([[ -5.568553139,-0.2176354,6.616517364,-6.14831,-0.676445955,7.363430104,2.473055478,3.530614113,1.962967643,1.0751715,0.685424684,-1.548385003,5.515144248,4.745380353,9.152159584,-18.62200831,-18.92248977,-8.725407005,6.864371745,16.02666315,18.42691566,51.07100434,0.004057261,0.42382406,1.85990684,3.944417716,1.514838706,1.982302809,1.301824793,5.7581537,2.139199848,6.64858383,6.14831,0.700429281,7.363668127,1.991813132,2.816741745,1.851392035,0.076331442,2.21053883,-0.991061417,6.73227767,5.245096613,5.793986403,0.040386163,0.03791706,0.941755908,18.62200831,18.92248977,18.42691566,31.74326038,97.25709386,56.15712605,2.593038885,961.6895929,959.096554,0,97.25709386]], dtype = 'float32')\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_results = regressor.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.775802]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.775808]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
